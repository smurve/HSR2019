{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow_transform.tf_metadata import dataset_schema\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High Performance Input Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_spec = {\n",
    "    'beta1': tf.io.FixedLenFeature([1], tf.float32),\n",
    "    'beta2': tf.io.FixedLenFeature([1], tf.float32),\n",
    "    'weekday': tf.io.FixedLenFeature([1], tf.int64),\n",
    "    'hour': tf.io.FixedLenFeature([1], tf.int64),\n",
    "    'humidity': tf.io.FixedLenFeature([1], tf.float32)\n",
    "}\n",
    "schema = dataset_schema.from_feature_spec(feature_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_tfr_input_fn(filename_pattern, batch_size, options):\n",
    "    \n",
    "    def _input_fn():\n",
    "        dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "            file_pattern=filename_pattern,\n",
    "            batch_size=batch_size,\n",
    "            features=feature_spec,\n",
    "            shuffle_buffer_size=options['shuffle_buffer_size'],\n",
    "            prefetch_buffer_size=options['prefetch_buffer_size'],\n",
    "            reader_num_threads=options['reader_num_threads'],\n",
    "            parser_num_threads=options['parser_num_threads'],\n",
    "            sloppy_ordering=options['sloppy_ordering'],\n",
    "            num_epochs=options['num_epochs'],\n",
    "            label_key='humidity')\n",
    "\n",
    "        if options['distribute']:\n",
    "            return dataset \n",
    "        else:\n",
    "            return dataset.make_one_shot_iterator().get_next()\n",
    "    return _input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the pattern from ```Beam_Pipelines.ipynb```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\wgi\\\\AppData\\\\Local\\\\Temp\\\\tmpj9tjlo0n\\\\training.tfr-*'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('temp_dir.txt') as file:\n",
    "    temp_dir = file.read()\n",
    "import os\n",
    "\n",
    "file_pattern = os.path.join(temp_dir, \"training.tfr-*\")\n",
    "file_pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_fn = make_tfr_input_fn(\n",
    "    filename_pattern=file_pattern,\n",
    "    batch_size=5, \n",
    "    options={'num_epochs': None,  # repeat infinitely\n",
    "             'shuffle_buffer_size': 1000,\n",
    "             'prefetch_buffer_size': 1000,\n",
    "             'reader_num_threads': 10,\n",
    "             'parser_num_threads': 10,\n",
    "             'sloppy_ordering': True,\n",
    "             'distribute': False})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This design pattern allows us to provide parameters to a function that is not allowed to take some. We essentially have a function now that provides its parameters to a *daughter* function as constants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later, we will provide this ```train_input_fn``` to the so-called ```estimator```. It is then up to the ```estimator``` to call ```train_input_fn``` and by that create the input-generating computational sub-graph within it's own graph and session context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For demonstration purposes, we call the function ourselves and see what it returns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples, labels = train_input_fn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beta1': <tf.Tensor 'IteratorGetNext_1:0' shape=(5, 1) dtype=float32>,\n",
       " 'beta2': <tf.Tensor 'IteratorGetNext_1:1' shape=(5, 1) dtype=float32>,\n",
       " 'hour': <tf.Tensor 'IteratorGetNext_1:2' shape=(5, 1) dtype=int64>,\n",
       " 'weekday': <tf.Tensor 'IteratorGetNext_1:3' shape=(5, 1) dtype=int64>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'IteratorGetNext_1:4' shape=(5, 1) dtype=float32>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, each time we evaluate ```samples``` and ```labels```, we'll get a new batch of 1000 samples with the associated 'humidity' labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    s, l = sess.run([samples, labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'beta1': array([[0.72565377],\n",
       "         [0.9101734 ],\n",
       "         [0.49424663],\n",
       "         [0.6305201 ],\n",
       "         [0.7068172 ]], dtype=float32), 'beta2': array([[0.427629  ],\n",
       "         [0.34223896],\n",
       "         [0.51290834],\n",
       "         [0.9161026 ],\n",
       "         [0.72738403]], dtype=float32), 'hour': array([[ 6],\n",
       "         [19],\n",
       "         [ 1],\n",
       "         [15],\n",
       "         [ 2]], dtype=int64), 'weekday': array([[6],\n",
       "         [1],\n",
       "         [0],\n",
       "         [4],\n",
       "         [0]], dtype=int64)}, array([[24.30971 ],\n",
       "        [30.72461 ],\n",
       "        [18.430576],\n",
       "        [27.431845],\n",
       "        [22.129492]], dtype=float32))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
