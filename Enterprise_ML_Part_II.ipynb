{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ZÃ¼hlke](./images/zuehlke_logo_rgb_small.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Enterprise Ready: Part II\n",
    "\n",
    "#### Coding for ML use cases\n",
    "#### Repeated content is inevitable and intended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resources:\n",
    "\n",
    "[The code for this lecture](https://github.com/smurve/HSR2019)\n",
    "\n",
    "#### Academic References\n",
    "\n",
    "[TensorFlow:\n",
    "Large-Scale Machine Learning on Heterogeneous Distributed Systems, Abadi et al 2016](https://arxiv.org/pdf/1603.04467.pdf)\n",
    "\n",
    "[TensorFlow Estimators:..., Cheng et al 2017](https://arxiv.org/pdf/1708.02637.pdf)\n",
    "\n",
    "#### Popular References\n",
    "[Blog: Framework Comparison (TF, Theano, Keras, DL4J, and others), towardsdatascience.com ](https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a)\n",
    "\n",
    "[Tensorflow Documentation](https://tensorflow.org)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What happened before\n",
    "#### Data Engineering is Software Engineering\n",
    "#### Architectural View on ML in the Enterprise\n",
    "#### Parallelize with Computational Graphs\n",
    "#### Storing and Retrieving Terabytes\n",
    "#### ML Engineering: Data for the Data Scientist\n",
    "#### The Estimator Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "#### 1) Requirements Engineering\n",
    "#### 1) HPE: High Performance Engineering\n",
    "#### 2) Apache Beam Programming Model\n",
    "#### 3) TF Transform\n",
    "#### 4) Ingesting data - fast\n",
    "#### 5) The Estimator Concept\n",
    "#### 6) Runtime Considerations\n",
    "#### 7) SWE & CI/CD in the Context of Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Return of the Baking Powder Machine\n",
    "<img src=\"images/baking-powder-packing-machine-500x500.jpg\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In the previous exercise...\n",
    "![measurements](images/measurements.png)\n",
    "\n",
    "We tried the hyptothesis:\n",
    "$$\n",
    "h= A_1 \\cdot \\beta_1 + A_2 \\cdot \\beta_2 + C\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ... we failed to explain the data\n",
    "![errors](images/systematic_error.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements Engineering\n",
    "#### Build a high-performance training application for the data scientists' model\n",
    "#### F1: Provide the input data at high speed in the desired $170$-dimensional format \n",
    "#### F2: Reuse transformations from the preprocessing pipeline\n",
    "#### F3: Monitor performance as the training continues\n",
    "#### F4: Use save points to protect valuable intermediate results\n",
    "#### F5: Provide a simple interface to the model (hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## High Performance Engineering\n",
    "#### Mama, look: No for-loops!\n",
    "#### Pre-compute and lookup\n",
    "#### Use Hardware efficiently with dedicated libraries\n",
    "#### Program in computational graphs that can be executed anywhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mama look: No for-loops\n",
    "See [collateral/No_For_Loops.ipynb](collateral/No_For_Loops.ipynb) for more.\n",
    "\n",
    "#### The classical approach:\n",
    "```\n",
    "def count_num_samples_with_row_of_3_with_forloop(samples):\n",
    "    sum = 0\n",
    "    for sample in samples:\n",
    "        for r in range(3):\n",
    "            for c in range(3):\n",
    "                if sample[r][c]==1 and sample[r+1][c+1]==1 and sample[r+2][c+2]== 1:\n",
    "                    sum+=1\n",
    "    return sum\n",
    "```\n",
    "\n",
    "#### A super-fast one-liner\n",
    "```\n",
    "np.sum(np.matmul(detector, np.transpose(np.reshape(samples, [2000, 25])))==3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensors and Graphs of Tensors\n",
    "#### [collateral/Tensors_Graphs_Sessions.ipynb](collateral/Tensors_Graphs_Sessions.ipynb)\n",
    "\n",
    "## Structural elements\n",
    "#### ```Placeholder```s take regular numbers and arrays as input for execution ($x$)\n",
    "#### ```Constant```s represent numbers that are known before execution time.\n",
    "#### ```Variable```s can be changed during graph execution\n",
    "#### All operators create operator nodes, rather than execute directly\n",
    "#### ```tf.gradient(...)``` provides means for gradient computations.\n",
    "#### ```Graph```s represent the structure of a subset of tensors.\n",
    "#### ```Session```s represent the *current* state of a ```Graph```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Tensorflow Code Example\n",
    "```\n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(shape=(None,1), dtype=tf.float32)\n",
    "a = tf.Variable([[.5]], name=\"weights\", dtype=tf.float32)\n",
    "b = tf.Variable([[-2.]], name=\"bias\", dtype=tf.float32)\n",
    "y = tf.matmul(x, a) + b\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(y, feed_dict={x: [[2.0], [4.0]]}))\n",
    "``` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Processing Pipelines\n",
    "#### Built for highly optimized parallel execution of massive workloads\n",
    "#### Apache Beam somewhat de facto standard\n",
    "#### Alternatives: Spark, Storm, ...\n",
    "#### Same interface in batch and real-time (only Java) mode.\n",
    "#### Functional Semantics: ```Map(...)``` and ```FlatMap(...)```\n",
    "#### Nodes must produce serializable output\n",
    "#### Pipelines support *fork* and *join* architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Apache Beam Pipeline Code\n",
    "```\n",
    "with beam.Pipeline('DirectRunner', PipelineOptions()) as p:\n",
    "\n",
    "    csv_encoder = tft.coders.CsvCoder(ORDERED_SIGNATURE_COLUMNS, schema)    \n",
    "\n",
    "    _ = (p \n",
    "         | 'read_from_csv' >> beam.io.ReadFromText(\n",
    "             file_pattern=signature_csv_train, coder=csv_encoder, skip_header_lines=1)\n",
    "         \n",
    "         | 'process_records' >> beam.Map(process_data)\n",
    "         \n",
    "         | 'write_to_csv' >> beam.io.WriteToText(\n",
    "             file_path_prefix=training_csv, coder=csv_encoder, header=header)\n",
    "        )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Production Beam Pipeline in action\n",
    "<img src=\"images/Dataflow.png\" style=\"width: 600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analyze and Transform\n",
    "\n",
    "#### Scaling requires first evaluating $min_k$ and $max_k$\n",
    "#### And then, in a second run, compute\n",
    "\n",
    "$$\n",
    "\\beta_{i,k}^\\prime = \\frac{\\beta_{i,k} - min_k(\\beta_{i,k})}\n",
    "{max_k(\\beta_{i,k}) - min_k(\\beta_{i,k})}\n",
    "$$\n",
    "\n",
    "The ```tf.transform``` library achieves all of that with a single line of code:\n",
    "\n",
    "```\n",
    "def process_data(row):\n",
    "    for c in ['beta1', 'beta2']:\n",
    "        row[c] = tft.scale_to_0_1(row[c])\n",
    "    return row\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Re-use the transform function\n",
    "#### The transform function can be saved for re-use at prediction time:\n",
    "\n",
    "```\n",
    "data_and_metadata, transform_fn = ( \n",
    "    signature_data | \"AnalyzeAndTransform\" \n",
    "    >> beam_impl.AnalyzeAndTransformDataset(process_data))\n",
    "```\n",
    "\n",
    "```\n",
    "#\n",
    "# Eventually, save the transform function for re-use at prediction time.\n",
    "#\n",
    "_ = (transform_fn | 'WriteTransformFn' \n",
    "     >> transform_fn_io.WriteTransformFn(metadata_dir))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Signature vs Training stage\n",
    "#### *Signature* data is what comes during prediction time\n",
    "#### It obeys the interface signature of the prediction service\n",
    "#### *Training* data is pre-processed to facilitate effective training\n",
    "#### The differences must be carefully dealt with\n",
    "#### Failure to do so results in the so-called *training-serving skew*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Requirements for Input Functions\n",
    "#### Process any number of files\n",
    "#### Create a continuous stream of decoded records\n",
    "#### Repeat the data stream (epochs)\n",
    "#### Shuffle the data to stabilize learning\n",
    "#### split the data in efficient batch sizes\n",
    "#### automatically iterate over those batches\n",
    "#### prefetch data, use multiple threads in parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use frameworks for infrastructure requirements\n",
    "See: [collateral/InputFunctions.ipynb](collateral/InputFunctions.ipynb)\n",
    "```\n",
    "def _input_fn():\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=filename_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=feature_spec,\n",
    "        shuffle_buffer_size=options['shuffle_buffer_size'],\n",
    "        prefetch_buffer_size=options['prefetch_buffer_size'],\n",
    "        reader_num_threads=options['reader_num_threads'],\n",
    "        parser_num_threads=options['parser_num_threads'],\n",
    "        sloppy_ordering=options['sloppy_ordering'],\n",
    "        num_epochs=options['num_epochs'],\n",
    "        label_key='humidity')\n",
    "    \n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "[collateral/Feature_Engineering.ipynb](collateral/Feature_Engineering.ipynb)\n",
    "#### Data in files are not always ideally encoded for ML\n",
    "#### Categorical data has to be transformed to numerical data\n",
    "#### Days and hours are best *one-hot* encoded\n",
    "#### Feature crosses help detect non-trivial dependencies (e.g. hour of week)\n",
    "#### Embeddings help reduce dimensions for large sparse input\n",
    "#### These re-encodings trade memory or speed for effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating an input layer for the model\n",
    "#### ```input_layer```: the $x$-interface to the data scientist's work\n",
    "```\n",
    "weekday = categorical_column_with_identity('weekday', num_buckets=7)\n",
    "hour = categorical_column_with_identity('hour', num_buckets=24)\n",
    "hour_of_week = indicator_column(crossed_column([weekday, hour], 24*7))\n",
    "```\n",
    "\n",
    "```\n",
    "all_feature_columns = [beta1, beta2, hour_of_week]\n",
    "\n",
    "input_layer = tf.feature_column.input_layer( \n",
    "    features, \n",
    "    feature_columns=[beta1, beta2, hour_of_week])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entering the *black box* of ML\n",
    "<img src=\"images/ML_a_small_fraction.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From 4 numbers per record create 170\n",
    "```\n",
    "array([[0.8050443 , 0.8593288 , 0.        , 0.        , 1.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/TF_programming_model.png\" style=\"width: 700px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensorflow Estimator\n",
    "#### The estimator manages graph, session, checkpoints, logging and lifecycle\n",
    "#### The estimator MUST create all tensors in its own context\n",
    "#### We provide functions that create tensors - for the estimator to call\n",
    "- We provide a model function (or maybe, the data scientist)\n",
    "- We provide input functions \n",
    "- We provide specifications for the lifecycle\n",
    "- We provide a general configuration\n",
    "- We provide an exporter that saves the entire graph (incl. transform functions!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The model function\n",
    "```\n",
    "def model_function(features, labels, mode):\n",
    "\n",
    "    my_input_layer = input_layer(features)\n",
    "    linreg = tf.layers.Dense(name=\"LinReg\", units=1)\n",
    "    hypothesis =linreg(my_input_layer)\n",
    "\n",
    "    #\n",
    "    # For predictions, we just need the hypothesis.\n",
    "    #\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            tf.estimator.ModeKeys.PREDICT, \n",
    "            predictions=hypothesis)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The model function for training\n",
    "```\n",
    "    ...\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-0)\n",
    "    train_op = optimizer.minimize(loss,...)\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(  \n",
    "        tf.estimator.ModeKeys.TRAIN,\n",
    "        loss = loss,\n",
    "        train_op = train_op)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Construct the estimator\n",
    "```\n",
    "config = RunConfig(\n",
    "    model_dir              = model_dir,\n",
    "    save_summary_steps     = 1,\n",
    "    save_checkpoints_steps = 100,\n",
    "    log_step_count_steps   = 10)\n",
    "    \n",
    "estimator = tf.estimator.Estimator(\n",
    "    config=config,\n",
    "    model_fn=model_function)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let it train\n",
    "```\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=train_input_fn, \n",
    "    max_steps=max_steps)\n",
    "\n",
    "...\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec=train_spec,\n",
    "    eval_spec=eval_spec)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the trained model\n",
    "```\n",
    "estimator = tf.contrib.predictor.from_saved_model(latest_model)\n",
    "\n",
    "sample = {\n",
    "    'beta1': [[1.234],[1.234]],\n",
    "    'beta2': [[1.234],[1.234]],\n",
    "    'weekday': [[5], [6]],\n",
    "    'hour': [[16], [17]]\n",
    "}\n",
    "\n",
    "result = estimator(sample)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can explain the data\n",
    "![errors](images/gaussian_error.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model is able to predict the anomalies\n",
    "![heatmap](images/Heatmap.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
