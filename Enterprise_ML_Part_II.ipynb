{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![ZÃ¼hlke](./images/zuehlke_logo_rgb_small.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning - Enterprise Ready: Part II\n",
    "\n",
    "#### Coding for ML use cases\n",
    "#### Repeated content is inevitable and intended"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Resources:\n",
    "\n",
    "[The code for this lecture](https://github.com/smurve/HSR2019)\n",
    "\n",
    "#### Academic References\n",
    "\n",
    "[TensorFlow:\n",
    "Large-Scale Machine Learning on Heterogeneous Distributed Systems, Abadi et al 2016](https://arxiv.org/pdf/1603.04467.pdf)\n",
    "\n",
    "[TensorFlow Estimators:..., Cheng et al 2017](https://arxiv.org/pdf/1708.02637.pdf)\n",
    "\n",
    "#### Popular References\n",
    "[Blog: Framework Comparison (TF, Theano, Keras, DL4J, and others), towardsdatascience.com ](https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a)\n",
    "\n",
    "[Tensorflow Documentation](https://tensorflow.org)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What happened before\n",
    "#### Data Engineering is Software Engineering\n",
    "#### Architectural View on ML in the Enterprise\n",
    "#### Parallelize with Computational Graphs\n",
    "#### Storing and Retrieving Terabytes\n",
    "#### ML Engineering: Data for the Data Scientist\n",
    "#### The Estimator Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Agenda\n",
    "#### 1) Requirements Engineering\n",
    "#### 1) HPE: High Performance Engineering\n",
    "#### 2) Apache Beam Programming Model\n",
    "#### 3) TF Transform\n",
    "#### 4) Ingesting data - fast\n",
    "#### 5) The Estimator Concept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The Return of the Baking Powder Machine\n",
    "<img src=\"images/baking-powder-packing-machine-500x500.jpg\" style=\"width: 400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### In the previous exercise...\n",
    "![measurements](images/measurements.png)\n",
    "\n",
    "We tried the hyptothesis:\n",
    "$$\n",
    "h= A_1 \\cdot \\beta_1 + A_2 \\cdot \\beta_2 + C\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### ... we failed to explain the data\n",
    "![errors](images/systematic_error.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Requirements Engineering\n",
    "#### Build a high-performance training application for the data scientists' model\n",
    "\n",
    "F1: Provide the input data at high speed in the desired $170$-dimensional format \n",
    "\n",
    "F2: Reuse transformations from the preprocessing pipeline\n",
    "\n",
    "F3: Monitor performance as the training continues\n",
    "\n",
    "F4: Use save points to protect valuable intermediate results\n",
    "\n",
    "F5: Provide a simple interface to the model (hypothesis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## High Performance Engineering\n",
    "\n",
    "Mama, look: No for-loops!\n",
    "\n",
    "Pre-compute and lookup\n",
    "\n",
    "Use Hardware efficiently with dedicated libraries\n",
    "\n",
    "Program in computational graphs that can be executed anywhere\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Mama look: No for-loops\n",
    "See [collateral/No_For_Loops.ipynb](collateral/No_For_Loops.ipynb) for more.\n",
    "\n",
    "#### The classical approach:\n",
    "```\n",
    "def count_num_samples_with_row_of_3_with_forloop(samples):\n",
    "    sum = 0\n",
    "    for sample in samples:\n",
    "        for r in range(3):\n",
    "            for c in range(3):\n",
    "                if sample[r][c]==1 and sample[r+1][c+1]==1 and sample[r+2][c+2]== 1:\n",
    "                    sum+=1\n",
    "    return sum\n",
    "```\n",
    "\n",
    "#### A super-fast one-liner\n",
    "```\n",
    "np.sum(np.matmul(detector, np.transpose(np.reshape(samples, [2000, 25])))==3)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Computational Graphs\n",
    "<img src=\"images/computational-graph.jpg\" style=\"width: 400px;\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensors and Graphs of Tensors\n",
    "\n",
    "[collateral/Tensors_Graphs_Sessions.ipynb](collateral/Tensors_Graphs_Sessions.ipynb)\n",
    "\n",
    "### Structural elements\n",
    "```Placeholder```s take regular numbers and arrays as input for execution ($x$)\n",
    "\n",
    "```Constant```s represent numbers that are known before execution time.\n",
    "\n",
    "```Variable```s can be changed during graph execution\n",
    "\n",
    "All operators create operator nodes, rather than execute directly\n",
    "\n",
    "```tf.gradient(...)``` provides means for gradient computations.\n",
    "\n",
    "```Graph```s represent the structure of a subset of tensors.\n",
    "\n",
    "```Session```s represent the *current* state of a ```Graph```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Tensorflow Code Example\n",
    "```\n",
    "import tensorflow as tf\n",
    "x = tf.placeholder(shape=(None,1), dtype=tf.float32)\n",
    "a = tf.Variable([[.5]], name=\"weights\", dtype=tf.float32)\n",
    "b = tf.Variable([[-2.]], name=\"bias\", dtype=tf.float32)\n",
    "y = tf.matmul(x, a) + b\n",
    "init = tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print(sess.run(y, feed_dict={x: [[2.0], [4.0]]}))\n",
    "``` \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Data Processing Pipelines\n",
    "\n",
    "Built for highly optimized parallel execution of massive workloads\n",
    "\n",
    "Apache Beam somewhat de facto standard\n",
    "\n",
    "Alternatives: Spark, Storm, ...\n",
    "\n",
    "Same interface in batch and real-time (only Java) mode.\n",
    "\n",
    "Functional Semantics: ```Map(...)``` and ```FlatMap(...)```\n",
    "\n",
    "Nodes must produce serializable output\n",
    "\n",
    "Pipelines support *fork* and *join* architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Apache Beam Pipeline Code\n",
    "```\n",
    "with beam.Pipeline('DirectRunner', PipelineOptions()) as p:\n",
    "\n",
    "    csv_encoder = tft.coders.CsvCoder(ORDERED_SIGNATURE_COLUMNS, schema)    \n",
    "\n",
    "    _ = (p \n",
    "         | 'read_from_csv' >> beam.io.ReadFromText(\n",
    "             file_pattern=signature_csv_train, coder=csv_encoder, skip_header_lines=1)\n",
    "         \n",
    "         | 'process_records' >> beam.Map(process_data)\n",
    "         \n",
    "         | 'write_to_csv' >> beam.io.WriteToText(\n",
    "             file_path_prefix=training_csv, coder=csv_encoder, header=header)\n",
    "        )\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A Production Beam Pipeline in action\n",
    "<img src=\"images/Dataflow.png\" style=\"width: 600px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analyze and Transform\n",
    "\n",
    "#### Scaling requires first evaluating $min_k$ and $max_k$\n",
    "#### And then, in a second run, compute\n",
    "\n",
    "$$\n",
    "\\beta_{i,k}^\\prime = \\frac{\\beta_{i,k} - min_k(\\beta_{i,k})}\n",
    "{max_k(\\beta_{i,k}) - min_k(\\beta_{i,k})}\n",
    "$$\n",
    "\n",
    "The ```tf.transform``` library achieves all of that with a single line of code:\n",
    "\n",
    "```\n",
    "def process_data(row):\n",
    "    for c in ['beta1', 'beta2']:\n",
    "        row[c] = tft.scale_to_0_1(row[c])\n",
    "    return row\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Re-use the transform function\n",
    "#### The transform function can be saved for re-use at prediction time:\n",
    "\n",
    "```\n",
    "data_and_metadata, transform_fn = ( \n",
    "    signature_data | \"AnalyzeAndTransform\" \n",
    "    >> beam_impl.AnalyzeAndTransformDataset(process_data))\n",
    "```\n",
    "\n",
    "```\n",
    "#\n",
    "# Eventually, save the transform function for re-use at prediction time.\n",
    "#\n",
    "_ = (transform_fn | 'WriteTransformFn' \n",
    "     >> transform_fn_io.WriteTransformFn(metadata_dir))\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Signature vs Training Stage\n",
    "- Reproduce all pre-processing steps during prediction!\n",
    "- Failure leads to \"training-serving skew\"\n",
    "\n",
    "<img src=\"images/Signature_vs_Training.png\" style=\"width: 500px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Signature vs Training stage\n",
    "*Signature* data is what comes during prediction time\n",
    "\n",
    "It obeys the interface signature of the prediction service\n",
    "\n",
    "*Training* data is pre-processed to facilitate effective training\n",
    "\n",
    "The differences must be carefully dealt with\n",
    "\n",
    "Failure to do so results in the so-called *training-serving skew*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Requirements for Input Functions\n",
    "\n",
    "Process any number of files\n",
    "\n",
    "Create a continuous stream of decoded records\n",
    "\n",
    "Repeat the data stream (epochs)\n",
    "\n",
    "Shuffle the data to stabilize learning\n",
    "\n",
    "Split the data in efficient batch sizes\n",
    "\n",
    "Automatically iterate over those batches\n",
    "\n",
    "Prefetch data, use multiple threads in parallel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Use frameworks for infrastructure requirements\n",
    "See: [collateral/InputFunctions.ipynb](collateral/InputFunctions.ipynb)\n",
    "```\n",
    "def _input_fn():\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=filename_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=feature_spec,\n",
    "        shuffle_buffer_size=options['shuffle_buffer_size'],\n",
    "        prefetch_buffer_size=options['prefetch_buffer_size'],\n",
    "        reader_num_threads=options['reader_num_threads'],\n",
    "        parser_num_threads=options['parser_num_threads'],\n",
    "        sloppy_ordering=options['sloppy_ordering'],\n",
    "        num_epochs=options['num_epochs'],\n",
    "        label_key='humidity')\n",
    "    \n",
    "    return dataset.make_one_shot_iterator().get_next()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Engineering\n",
    "[collateral/Feature_Engineering.ipynb](collateral/Feature_Engineering.ipynb)\n",
    "\n",
    "Data in files are not always ideally encoded for ML\n",
    "\n",
    "Categorical data has to be transformed to numerical data\n",
    "\n",
    "Days and hours are best *one-hot* encoded\n",
    "\n",
    "Feature crosses help detect non-trivial dependencies (e.g. hour of week)\n",
    "\n",
    "Embeddings help reduce dimensions for large sparse input\n",
    "\n",
    "These re-encodings trade memory or speed for effectiveness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Creating an input layer for the model\n",
    "#### ```input_layer```: the $x$-interface to the data scientist's work\n",
    "```\n",
    "weekday = categorical_column_with_identity('weekday', num_buckets=7)\n",
    "hour = categorical_column_with_identity('hour', num_buckets=24)\n",
    "hour_of_week = indicator_column(crossed_column([weekday, hour], 24*7))\n",
    "```\n",
    "\n",
    "```\n",
    "all_feature_columns = [beta1, beta2, hour_of_week]\n",
    "\n",
    "input_layer = tf.feature_column.input_layer( \n",
    "    features, \n",
    "    feature_columns=[beta1, beta2, hour_of_week])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entering the *black box* of ML\n",
    "<img src=\"images/ML_a_small_fraction.png\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## From 4 numbers per record create 170\n",
    "```\n",
    "array([[0.8050443 , 0.8593288 , 0.        , 0.        , 1.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
    "        ...\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<img src=\"images/TF_programming_model.png\" style=\"width: 700px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tensorflow Estimator\n",
    "#### The estimator manages graph, session, checkpoints, logging and lifecycle\n",
    "#### The estimator MUST create all tensors in its own context\n",
    "#### We provide functions that create tensors - for the estimator to call\n",
    "- We provide a model function (or maybe, the data scientist)\n",
    "- We provide input functions \n",
    "- We provide specifications for the lifecycle\n",
    "- We provide a general configuration\n",
    "- We provide an exporter that saves the entire graph (incl. transform functions!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The model function\n",
    "```\n",
    "def model_function(features, labels, mode):\n",
    "\n",
    "    my_input_layer = input_layer(features)\n",
    "    linreg = tf.layers.Dense(name=\"LinReg\", units=1)\n",
    "    hypothesis =linreg(my_input_layer)\n",
    "\n",
    "    #\n",
    "    # For predictions, we just need the hypothesis.\n",
    "    #\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(\n",
    "            tf.estimator.ModeKeys.PREDICT, \n",
    "            predictions=hypothesis)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The model function for training\n",
    "```\n",
    "    ...\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-0)\n",
    "    train_op = optimizer.minimize(loss,...)\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(  \n",
    "        tf.estimator.ModeKeys.TRAIN,\n",
    "        loss = loss,\n",
    "        train_op = train_op)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Construct the estimator\n",
    "```\n",
    "config = RunConfig(\n",
    "    model_dir              = model_dir,\n",
    "    save_summary_steps     = 1,\n",
    "    save_checkpoints_steps = 100,\n",
    "    log_step_count_steps   = 10)\n",
    "    \n",
    "estimator = tf.estimator.Estimator(\n",
    "    config=config,\n",
    "    model_fn=model_function)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Let it train\n",
    "```\n",
    "train_spec = tf.estimator.TrainSpec(\n",
    "    input_fn=train_input_fn, \n",
    "    max_steps=max_steps)\n",
    "\n",
    "...\n",
    "\n",
    "tf.estimator.train_and_evaluate(\n",
    "    estimator,\n",
    "    train_spec=train_spec,\n",
    "    eval_spec=eval_spec)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Using the trained model\n",
    "```\n",
    "estimator = tf.contrib.predictor.from_saved_model(latest_model)\n",
    "\n",
    "sample = {\n",
    "    'beta1': [[1.234],[1.234]],\n",
    "    'beta2': [[1.234],[1.234]],\n",
    "    'weekday': [[5], [6]],\n",
    "    'hour': [[16], [17]]\n",
    "}\n",
    "\n",
    "result = estimator(sample)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Now, we can explain the data\n",
    "![errors](images/gaussian_error.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The model is able to predict the anomalies\n",
    "![heatmap](images/Heatmap.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
